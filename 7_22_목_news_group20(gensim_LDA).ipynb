{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7/22 목-news_group20(gensim_LDA).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fB_3DMwlElC0lYr7AYp7JeM2KyUbKU2i",
      "authorship_tag": "ABX9TyOio/kuk5EzkjkLDkmNs/33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunicecream/Natural-Language-Processing-NLP-/blob/main/7_22_%EB%AA%A9_news_group20(gensim_LDA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cItM9lZKHrZo",
        "outputId": "26ffd6ee-5ea7-41b4-9666-1b0c353dc02c"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"news_group20(gensim_LDA).ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1_NWeJQyC1qqcMwFAxWX0bVHgd-KqOt9h\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Latent Dirichlet Allocation (LDA)\n",
        "# ---------------------------------\n",
        "import numpy as np\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamodel import LdaModel as LDA\n",
        "\n",
        "# %cd '/content/drive/MyDrive/Colab Notebooks'\n",
        "\n",
        "# 전처리가 완료된 한글 코퍼스를 읽어온다.\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/pickle/newsgroup20.pkl', 'rb') as f:\n",
        "    subject, text, target = pickle.load(f)\n",
        "\n",
        "n_target = len(set(target)) #20개"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j85W23-eKa7o",
        "outputId": "24af06e2-72f6-47a3-b65b-036f90488d5e"
      },
      "source": [
        "# doc2bow 생성\n",
        "text_tok = [t.split() for t in text]\n",
        "vocab = corpora.Dictionary(text_tok)\n",
        "dict(list(vocab.items())[:10])\n",
        "news_bow = [vocab.doc2bow(s) for s in text_tok]\n",
        "print(news_bow[0])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX61_99kKb6N"
      },
      "source": [
        "# Latent Dirichlet Allocation (LDA)\n",
        "# ---------------------------------\n",
        "model = LDA(news_bow, num_topics = n_target, id2word=vocab)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGsuObeQKcxv",
        "outputId": "1f206cc9-edf2-436f-c3f9-a476ed484b46"
      },
      "source": [
        "# 문서 별 Topic 번호를 확인한다. (문서 10개만 확인)\n",
        "doc_topic = model.get_document_topics(news_bow)\n",
        "for i in range(10):\n",
        "    dp = np.array(doc_topic[i])\n",
        "    most_likely_topic = int(dp[np.argmax(dp[:, 1]), 0])\n",
        "    print('문서-{:d} : topic = {:02d}, target = {:02d}'.format(i, most_likely_topic, target[i]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문서-0 : topic = 18, target = 17\n",
            "문서-1 : topic = 16, target = 00\n",
            "문서-2 : topic = 03, target = 17\n",
            "문서-3 : topic = 03, target = 11\n",
            "문서-4 : topic = 09, target = 10\n",
            "문서-5 : topic = 07, target = 15\n",
            "문서-6 : topic = 08, target = 04\n",
            "문서-7 : topic = 17, target = 17\n",
            "문서-8 : topic = 16, target = 13\n",
            "문서-9 : topic = 01, target = 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbb-q3rOKdIl",
        "outputId": "0526d2dd-3c27-4ab7-c70e-44235c49aaf3"
      },
      "source": [
        "# topic_term 행렬에서 topic 별로 중요 단어를 표시한다\n",
        "topic_term = model.get_topic_terms(0, topn=10)\n",
        "for i in range(n_target):\n",
        "    topic_term = model.get_topic_terms(i, topn=10)\n",
        "    idx = [idx for idx, score in topic_term]\n",
        "    print('토픽-{:2d} : '.format(i+1), end='')\n",
        "    for n in idx:\n",
        "        print('{:s} '.format(vocab[n]), end='')\n",
        "    print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "토픽- 1 : studi number line need imag power percentag limit packag espn \n",
            "토픽- 2 : want driver need advic sale softwar secur use look clipper \n",
            "토픽- 3 : christian year moral armenian opinion burn dividian ranch worst survivor \n",
            "토픽- 4 : question good code tap israel jesu anim expans ultra stand \n",
            "토픽- 5 : atheist polit control clinton free order open letter hall drive \n",
            "토픽- 6 : waco batf cheap today murder everyon almost find video fast \n",
            "토픽- 7 : graphic secret mormon algorithm clipper chip realli jew escrow next \n",
            "토픽- 8 : updat post scsi centri drive comput hard pleas repost acceler \n",
            "토픽- 9 : space thought set food reason keyboard local list modem advertis \n",
            "토픽-10 : question good time test automot concept dumbest frequent neighbor would \n",
            "토픽-11 : info need part price sale right list mail window util \n",
            "토픽-12 : window system plu stat bike chang select printer technic best \n",
            "토픽-13 : problem game player turkish could jewish basebal shoot armenia say \n",
            "토픽-14 : sale clipper chip announc white hous text encrypt team font \n",
            "토픽-15 : hell forsal arrog hezbollah christian mani scienc speed tradit homeopathi \n",
            "토픽-16 : monitor mous islam rushdi gateway predict doubl inimit easter sale \n",
            "토픽-17 : card work like file american sensit superstit express answer report \n",
            "토픽-18 : read pleas appl playoff warn tape disk radar detector cryptographi \n",
            "토픽-19 : long isra final first give book terror solut color moon \n",
            "토픽-20 : help manag need window want drive insur public problem intern \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sT5DdL2Kr9F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}