{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-14.naver_movie(kogpt2_2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Nvk0_bIBUFJz9zdrtoRe3kR10v0fvoRW",
      "authorship_tag": "ABX9TyOiAgZe+yebH0npzGa/i7WO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunicecream/Natural-Language-Processing-NLP-/blob/main/8_14_naver_movie(kogpt2_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h7WdtIG3d5Y",
        "outputId": "f8f09dd2-f51a-4e86-ac69-3e1772443088"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 11 06:22:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff5a_7bG3euE",
        "outputId": "d3d7dcfb-1d68-4a65-dd94-1231b3bb17a2"
      },
      "source": [
        "!pip install --upgrade mxnet>=1.6.0\n",
        "!pip install gluonnlp\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 344 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595730 sha256=bc826c4607b02268e452ab20ae921d9bfc62abc42a6471a271a0c3e6e7119c1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 53.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ9HxT0F19hB"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"8-14.naver_movie(kogpt2_2).ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1oz7cwQ6Wv116SfshytDb3w68i_oaK7W6\n",
        "\"\"\"\n",
        "\n",
        "# KoGPT2를 이용한 네이버 영화 감성분석\n",
        "# 참고 : https://github.com/SKT-AI/KoGPT2\n",
        "# !pip install --upgrade mxnet>=1.6.0\n",
        "# !pip install gluonnlp\n",
        "# !pip install transformers\n",
        "# !pip install sentencepiece\n",
        "\n",
        "import gluonnlp as nlp\n",
        "from gluonnlp.data import SentencepieceTokenizer, SentencepieceDetokenizer\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "raSbIKaL3ot1",
        "outputId": "dbe645be-e443-40c8-cdb8-c5d455b41bd2"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %cd '/content/drive/MyDrive/Colab Notebooks'\n",
        "df = pd.read_csv('/content/drive/MyDrive/머신러닝/GPT/naver_ratings.txt', header=0, delimiter='\\t', quoting=3)\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT4K2jQd33Z_"
      },
      "source": [
        "# \"\\d+\"는 숫자 1개 이상을 의미함. 모든 숫자를 공백으로 치환\n",
        "df['document'] = df['document'].apply(lambda x: re.sub(r\"\\d+\", \" \", x))\n",
        "df.drop('id', axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NpLLg7z34zR"
      },
      "source": [
        "document = list(df['document'])\n",
        "label = list(df['label'])\n",
        "dx_train, dx_test, dy_train, dy_test = train_test_split(document, label, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq1cU0l135mR"
      },
      "source": [
        "MY_PATH = '/content/drive/MyDrive/머신러닝/GPT/gpt_ckpt/'\n",
        "MODEL_PATH = MY_PATH \n",
        "TOKENIZER_PATH = MY_PATH + 'gpt2_kor_tokenizer.spiece'\n",
        "\n",
        "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH, num_best=0, alpha=0)\n",
        "detokenizer = SentencepieceDetokenizer(TOKENIZER_PATH)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(TOKENIZER_PATH,\n",
        "                                               mask_token = None,\n",
        "                                               sep_token = None,\n",
        "                                               cls_token = None,\n",
        "                                               unknown_token = '<unk>',\n",
        "                                               padding_token = '<pad>',\n",
        "                                               bos_token = '<s>',\n",
        "                                               eos_token = '</s>')\n",
        "# vocab --> Vocab(size=50000, unk=\"<unk>\", reserved=\"['<pad>', '<s>', '</s>']\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErATYm-93y9j",
        "outputId": "3e052a01-8697-4409-e1e2-671ecc8b3a92"
      },
      "source": [
        "MAX_LEN = 60\n",
        "\n",
        "def build_data(x_data, y_label):\n",
        "    data_sents = []\n",
        "    data_labels = []\n",
        "\n",
        "    for sent, label in zip(x_data, y_label):\n",
        "        tokenized_text = vocab[tokenizer(sent)]\n",
        "\n",
        "        tokens = [vocab[vocab.bos_token]]   # 시작 = <s>\n",
        "        tokens += pad_sequences([tokenized_text], \n",
        "                                MAX_LEN, \n",
        "                                value=vocab[vocab.padding_token], \n",
        "                                padding='post').tolist()[0] \n",
        "        tokens += [vocab[vocab.eos_token]]  # 끝 = </s>\n",
        "\n",
        "        data_sents.append(tokens)\n",
        "        data_labels.append(label)\n",
        "\n",
        "    return np.array(data_sents, dtype=np.int64), np.array(data_labels, dtype=np.int64).reshape(-1, 1)\n",
        "\n",
        "# 시험용으로 100개씩만 사용한다.\n",
        "x_train, y_train = build_data(dx_train[:100], dy_train[:100])\n",
        "x_test, y_test = build_data(dx_test[:100], dy_test[:100])\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
        "\n",
        "x_test[0]\n",
        "\n",
        "len(x_test[0])\n",
        "\n",
        "print(len(vocab))\n",
        "print(vocab.padding_token, ':', vocab[vocab.padding_token])\n",
        "print(vocab.bos_token, ': ', vocab[vocab.bos_token])\n",
        "print(vocab.eos_token, ': ', vocab[vocab.eos_token])\n",
        "print(vocab.unknown_token, ': ', vocab[vocab.unknown_token])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "<pad> : 3\n",
            "<s> :  0\n",
            "</s> :  1\n",
            "<unk> :  5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X6ez0T7q3yGY",
        "outputId": "9c8bd8ea-1f70-4ef4-9c7f-d62960c14d5e"
      },
      "source": [
        "word2idx = {k:v for k, v in vocab.token_to_idx.items()}\n",
        "idx2word = {v:k for k, v in word2idx.items()}\n",
        "idx2word[5000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'▁전세'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dabn52eR3v5G",
        "outputId": "c968ebb5-f31b-4afd-ae73-f91a0e597f40"
      },
      "source": [
        "# 참고 : https://nlp.gluon.ai/api/modules/data.html\n",
        "sub_word = tokenizer('나는 자연어처리를 공부하고 있다')\n",
        "print(sub_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁나는', '▁자연', '어', '처리를', '▁공부하고', '▁있다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kSfEkeu3vYb",
        "outputId": "a77d023d-1000-47df-e2b7-f56442ce8954"
      },
      "source": [
        "sent_idx = vocab[sub_word]\n",
        "print(sent_idx)\n",
        "\n",
        "print(detokenizer(sub_word))\n",
        "\n",
        "print([idx2word[i] for i in x_test[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3918, 1582, 47487, 29455, 36076, 123]\n",
            "나는 자연어처리를 공부하고 있다\n",
            "['<s>', '▁지금까지', '▁미국이', '▁내', '머리', '속을', '▁지배', '했다는', '생각', '에', '▁화가', '난다', '...', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '</s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMOA3IHa3wu1",
        "outputId": "a08d5038-e43e-47aa-bea1-6f55fa385cf4"
      },
      "source": [
        "gpt_model = TFGPT2LMHeadModel.from_pretrained(MODEL_PATH)\n",
        "gpt_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/머신러닝/GPT/gpt_ckpt/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tfgp_t2lm_head_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "transformer (TFGPT2MainLayer multiple                  124242432 \n",
            "=================================================================\n",
            "Total params: 124,242,432\n",
            "Trainable params: 124,242,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9oKbjHH3waf",
        "outputId": "c7fc7252-cc31-43de-bff3-7a5f982d4777"
      },
      "source": [
        "# TFGPT2MainLayer는 fine-tuning을 하지 않는다.\n",
        "gpt_model.trainable = False\n",
        "gpt_model.summary() # gtp_model을 다시 확인한다. trainable params = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tfgp_t2lm_head_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "transformer (TFGPT2MainLayer multiple                  124242432 \n",
            "=================================================================\n",
            "Total params: 124,242,432\n",
            "Trainable params: 0\n",
            "Non-trainable params: 124,242,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHrtplc3rtk",
        "outputId": "923508c9-23f1-49b6-bec2-78399812406a"
      },
      "source": [
        "# GPT2 입력\n",
        "# ---------\n",
        "x_input = Input(batch_shape = (None, MAX_LEN + 2), dtype = tf.int32)  # <s>와 </s> 2개 포함\n",
        "\n",
        "# GPT2 출력\n",
        "# ---------\n",
        "# for classification\n",
        "# output_gpt[0]           --> <KerasTensor: shape=(None, 62, 50000) dtype=float32\n",
        "# output_gpt[0][:, -1, :] --> <KerasTensor: shape=(None, 50000) dtype=float32\n",
        "#\n",
        "# output_gpt 전체 출력 :\n",
        "# TFCausalLMOutputWithPast([('logits',\n",
        "#                            <KerasTensor: shape=(None, 62, 50000) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>),\n",
        "#                           ('past_key_values',\n",
        "#                            (<KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>,\n",
        "#                             <KerasTensor: shape=(2, None, 12, 62, 64) dtype=float32 (created by layer 'tfgp_t2lm_head_model')>))])\n",
        "# past_key_values : 중간 출력\n",
        "# (2, None, 12, 62, 64)\n",
        "# 2 : Text prediction과 Task classifier (GPT-1 논문의 figure-1)\n",
        "# None : batch\n",
        "# 12 : number of layers\n",
        "# 62 : MAX_LEN\n",
        "# 64 : d_model / num_heads = 768 / 12 = 64 = dk <-- multi-head attention의 각 head의 출력\n",
        "#      64개 head를 concat으로 묶으면 768 embedding vector size.\n",
        "#\n",
        "# https://opensourcelibs.com/lib/kogpt2#mxnet-gluon\n",
        "# GPT2Model(units=768,\n",
        "#     max_length=1024,\n",
        "#     num_heads=12,\n",
        "#     num_layers=12,\n",
        "#     dropout=0.1,\n",
        "#     vocab_size=50000)\n",
        "output_gpt = gpt_model(x_input)\n",
        "\n",
        "# 'past_key_values' 출력을 이용한다.\n",
        "# 마지막 layer의 multi head attension 출력\n",
        "output_mha = output_gpt[1][0][0, :, -1, :, :]\n",
        "for i in range(1, 12):\n",
        "    output_mha = Concatenate()([output_mha, output_gpt[1][i][0, :, -1, :, :]])\n",
        "output_mha = GlobalAveragePooling1D()(output_mha)\n",
        "\n",
        "# Downstream task : 네이버 영화 감성분석\n",
        "# -------------------------------------\n",
        "y_output = Dense(1, activation = 'sigmoid')(output_mha)\n",
        "model = Model(x_input, y_output)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = Adam(learning_rate = 0.001))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc4f84cbd70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc4f84cbd70>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fc52367f170> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fc52367f170> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 62)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tfgp_t2lm_head_model (TFGPT2LMH TFCausalLMOutputWith 124242432   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem (Slici (None, 62, 64)       0           tfgp_t2lm_head_model[0][1]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_1 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][2]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 62, 128)      0           tf.__operators__.getitem[0][0]   \n",
            "                                                                 tf.__operators__.getitem_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][3]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 62, 192)      0           concatenate[0][0]                \n",
            "                                                                 tf.__operators__.getitem_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_3 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][4]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 62, 256)      0           concatenate_1[0][0]              \n",
            "                                                                 tf.__operators__.getitem_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][5]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 62, 320)      0           concatenate_2[0][0]              \n",
            "                                                                 tf.__operators__.getitem_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_5 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][6]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 62, 384)      0           concatenate_3[0][0]              \n",
            "                                                                 tf.__operators__.getitem_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_6 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][7]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 62, 448)      0           concatenate_4[0][0]              \n",
            "                                                                 tf.__operators__.getitem_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_7 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][8]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 62, 512)      0           concatenate_5[0][0]              \n",
            "                                                                 tf.__operators__.getitem_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_8 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][9]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 62, 576)      0           concatenate_6[0][0]              \n",
            "                                                                 tf.__operators__.getitem_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_9 (Sli (None, 62, 64)       0           tfgp_t2lm_head_model[0][10]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 62, 640)      0           concatenate_7[0][0]              \n",
            "                                                                 tf.__operators__.getitem_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_10 (Sl (None, 62, 64)       0           tfgp_t2lm_head_model[0][11]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 62, 704)      0           concatenate_8[0][0]              \n",
            "                                                                 tf.__operators__.getitem_10[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_11 (Sl (None, 62, 64)       0           tfgp_t2lm_head_model[0][12]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 62, 768)      0           concatenate_9[0][0]              \n",
            "                                                                 tf.__operators__.getitem_11[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            769         global_average_pooling1d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 124,243,201\n",
            "Trainable params: 769\n",
            "Non-trainable params: 124,242,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGOIVoEP3pMk",
        "outputId": "8241ec48-6fb6-430a-8b0a-89e6fea0c9a3"
      },
      "source": [
        "hist = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=3, batch_size=1024)\n",
        "\n",
        "# 1/1 [==============================] - 14s 14s/step - loss: 0.7251 - val_loss: 70.8553\n",
        "# Epoch 2/3\n",
        "# 1/1 [==============================] - 1s 1s/step - loss: 69.2513 - val_loss: 26.5999\n",
        "# Epoch 3/3\n",
        "# 1/1 [==============================] - 1s 1s/step - loss: 25.5047 - val_loss: 21.4767"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.8697WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "1/1 [==============================] - 17s 17s/step - loss: 0.8697 - val_loss: 0.7157\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7105 - val_loss: 0.7475\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 437ms/step - loss: 0.7109 - val_loss: 0.8215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QSgJTjtU3s0J",
        "outputId": "6ccf8073-0384-4770-83c0-a559b130103b"
      },
      "source": [
        "# Loss history를 그린다\n",
        "plt.plot(hist.history['loss'], label='Train loss')\n",
        "plt.plot(hist.history['val_loss'], label = 'Test loss')\n",
        "plt.legend()\n",
        "plt.title(\"Loss history\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws7ggDSw3sim",
        "outputId": "1e4d0004-6fe7-47c5-a4a1-a6e331d1ed17"
      },
      "source": [
        "# 시험 데이터로 학습 성능을 평가한다\n",
        "pred = model.predict(x_test)\n",
        "y_pred = np.where(pred > 0.5, 1, 0)\n",
        "accuracy = (y_pred == y_test).mean()\n",
        "print(\"\\nAccuracy = %.2f %s\" % (accuracy * 100, '%'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "\n",
            "Accuracy = 46.00 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJtdL8D4Pt-"
      },
      "source": [
        "# gpt_model.trainable = True로 바꾸고, learning-rate를 작게 적용해서\n",
        "# 전체를 다시 학습한다. (미세 조정)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
