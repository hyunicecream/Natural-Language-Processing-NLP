{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습과제1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1vHRrZzm46VGvWOLCR2CI9gAI5Kr5ATyK",
      "authorship_tag": "ABX9TyOe+lsfrEXVZhouWI8npV+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunicecream/Natural-Language-Processing-NLP-/blob/main/%EC%8B%A4%EC%8A%B5%EA%B3%BC%EC%A0%9C1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHxNs5vK-tx9",
        "outputId": "7b1f6864-3c25-4ec4-f266-43c14276c0b1"
      },
      "source": [
        "%pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 40.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 14.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ7L_Qvb-8nj",
        "outputId": "d5ab0dbe-5873-4d4e-98ac-50e3795af630"
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import sentencepiece as spm\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# %cd '/content/drive/MyDrive/Colab Notebooks'\n",
        "\n",
        "# news data를 읽어온다. subject 분석용.\n",
        "newsData = fetch_20newsgroups(shuffle=True, random_state=1, remove=('footers', 'quotes'))\n",
        "# heard quotes, footer 만 있다 body 부분은 따로 없다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqviv6Tf--vo",
        "outputId": "d9c535b8-1731-4370-d412-541047df4401"
      },
      "source": [
        "# 첫 번째 news를 조회해 본다.\n",
        "news = newsData['data']\n",
        "topic = newsData['target']\n",
        "topic_name = newsData['target_names']\n",
        "n_topic = len(set(topic))\n",
        "\n",
        "print(len(news))\n",
        "print(news[0])\n",
        "print('topic = ', topic[0], topic_name[topic[0]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11314\n",
            "From: ab4z@Virginia.EDU (\"Andi Beyer\")\n",
            "Subject: Re: Israeli Terrorism\n",
            "Organization: University of Virginia\n",
            "Lines: 15\n",
            "topic =  17 talk.politics.mideast\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeoelYLc_DDo"
      },
      "source": [
        "# Subject만 추출한다.\n",
        "subjects = []\n",
        "for text in news:\n",
        "    for sent in text.split('\\n'):\n",
        "        idx = sent.find('Subject:')\n",
        "        if idx >= 0:       # found\n",
        "            subjects.append(sent[(idx + 9):].replace('Re: ', '').lower())\n",
        "           #subjects.append(re.sub(\"[^a-zA-Z]\", \" \", subject))\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe4DDf-9BH5U",
        "outputId": "180a706c-0e0a-4a63-da87-8d38c0c5e323"
      },
      "source": [
        "subjects[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['israeli terrorism',\n",
              " 'amusing atheists and agnostics',\n",
              " 'rejoinder. questions to israelis',\n",
              " 'clipper- business as usual?',\n",
              " 'playoff pool rule revision']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-8Ue-nZBKAl",
        "outputId": "5ae056a9-a2c5-4332-ce81-f5263885cbfa"
      },
      "source": [
        "len(subjects)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W0pw-4JJzX_",
        "outputId": "254db500-69c1-403c-b51c-a0a9a9470c30"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "subject_tok = [nltk.word_tokenize(subject) for subject in subjects]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWKqywAQMj9I",
        "outputId": "3178a5a9-e765-4c04-8788-a2ad2fa51251"
      },
      "source": [
        "subject_tok[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['israeli', 'terrorism'],\n",
              " ['amusing', 'atheists', 'and', 'agnostics'],\n",
              " ['rejoinder', '.', 'questions', 'to', 'israelis'],\n",
              " ['clipper-', 'business', 'as', 'usual', '?'],\n",
              " ['playoff', 'pool', 'rule', 'revision']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91VW6mDJNMLk"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(subject_tok)\n",
        "subjects_idx = tokenizer.texts_to_sequences(subject_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uC1It55YHcd",
        "outputId": "66d2ac7d-4e5e-4e48-9b36-53be11bf547b"
      },
      "source": [
        "word2idx = tokenizer.word_index\n",
        "idx2word = {v:k for k, v in word2idx.items()}\n",
        "print(\"사전크기 =\", len(word2idx))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "사전크기 = 7918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoB4Sr7WNmuC",
        "outputId": "9c2967d1-f9c6-42ae-b443-785fdcf80dee"
      },
      "source": [
        "subjects_idx[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[110, 285],\n",
              " [821, 68, 9, 900],\n",
              " [1078, 10, 61, 14, 690],\n",
              " [4665, 3321, 84, 1513, 1],\n",
              " [184, 509, 691, 3322]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KL6uBsKN2qP"
      },
      "source": [
        "paragraph_id = []\n",
        "for i in range(len(subjects_idx)):\n",
        "  paragraph_id.append(i)\n",
        "\n",
        "paragraph_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr8tBT_ATq3N"
      },
      "source": [
        "p_data = []\n",
        "w_data = []\n",
        "y_data = []\n",
        "for p_id, subject in zip(paragraph_id, subjects_idx):\n",
        "  if len(subject) < 4:\n",
        "    continue\n",
        "\n",
        "  for a, b, c, d in nltk.ngrams(subject, 4):\n",
        "    p_data.append(p_id)\n",
        "    w_data.append([a, b, c])\n",
        "    y_data.append(d)\n",
        "\n",
        "p_data = np.array(p_data).reshape(-1, 1)\n",
        "w_data = np.array(w_data)\n",
        "y_data = np.array(y_data).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvDfROHCVXmH",
        "outputId": "6d1493a5-9ef5-413e-ef97-fe945d6b48a1"
      },
      "source": [
        "p_data.shape, w_data.shape, y_data.shape\n",
        "\n",
        "print(p_data[5], w_data[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4] [184 509 691]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVPr4wD5V7af"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dropout, Concatenate, Average, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiaEIEOlWMuV",
        "outputId": "1e5d674a-73b4-4788-bd1b-cacf4ed39af6"
      },
      "source": [
        "p_size = len(paragraph_id)\n",
        "vocab_size = len(word2idx) + 1\n",
        "emb_size = 64\n",
        "\n",
        "p_input = Input(shape = (1, ))\n",
        "w_input = Input(shape = (3, ))\n",
        "\n",
        "p_emb = Embedding(p_size, emb_size, input_length=1, name=\"H\")(p_input)\n",
        "w_emb = Embedding(vocab_size, emb_size, input_length=3)(w_input)\n",
        "\n",
        "emb = Concatenate(axis=1)([p_emb, w_emb])\n",
        "flat = Flatten()(emb)\n",
        "\n",
        "y_output = Dense(vocab_size, activation='softmax')(flat)\n",
        "\n",
        "pvdm = Model([p_input, w_input], y_output)\n",
        "pvdm.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0001))\n",
        "pvdm.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "H (Embedding)                   (None, 1, 64)        724096      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 3, 64)        506816      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 64)        0           H[0][0]                          \n",
            "                                                                 embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 256)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7919)         2035183     flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,266,095\n",
            "Trainable params: 3,266,095\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSr2QscRZSKi",
        "outputId": "f5d91582-9076-43b8-c465-ba9e6ec7cd10"
      },
      "source": [
        "hist = pvdm.fit([p_data, w_data], y_data, epochs=30, batch_size=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "73/73 [==============================] - 2s 9ms/step - loss: 8.9695\n",
            "Epoch 2/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 8.9510\n",
            "Epoch 3/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 8.9271\n",
            "Epoch 4/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 8.8914\n",
            "Epoch 5/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 8.8367\n",
            "Epoch 6/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 8.7563\n",
            "Epoch 7/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 8.6470\n",
            "Epoch 8/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 8.5088\n",
            "Epoch 9/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 8.3439\n",
            "Epoch 10/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 8.1567\n",
            "Epoch 11/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 7.9514\n",
            "Epoch 12/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 7.7339\n",
            "Epoch 13/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 7.5095\n",
            "Epoch 14/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 7.2837\n",
            "Epoch 15/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 7.0629\n",
            "Epoch 16/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 6.8536\n",
            "Epoch 17/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 6.6610\n",
            "Epoch 18/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 6.4897\n",
            "Epoch 19/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 6.3414\n",
            "Epoch 20/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 6.2146\n",
            "Epoch 21/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 6.1054\n",
            "Epoch 22/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 6.0106\n",
            "Epoch 23/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 5.9257\n",
            "Epoch 24/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 5.8477\n",
            "Epoch 25/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 5.7745\n",
            "Epoch 26/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 5.7045\n",
            "Epoch 27/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 5.6362\n",
            "Epoch 28/30\n",
            "73/73 [==============================] - 1s 9ms/step - loss: 5.5692\n",
            "Epoch 29/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 5.5032\n",
            "Epoch 30/30\n",
            "73/73 [==============================] - 1s 8ms/step - loss: 5.4379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVq4cxahZaAm"
      },
      "source": [
        "d_matrix = pvdm.get_layer(\"H\").get_weights()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_Q0F0mQablZ",
        "outputId": "399771dc-17ef-454b-f2eb-345a52a95dc0"
      },
      "source": [
        "print(d_matrix)\n",
        "print(len(d_matrix))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00235636 -0.03846716 -0.03606053 ...  0.03939005 -0.0024717\n",
            "  -0.00049453]\n",
            " [ 0.07054433  0.05956949  0.04627699 ...  0.03640739  0.07339517\n",
            "  -0.02952627]\n",
            " [-0.00909832 -0.00662261 -0.01028945 ... -0.0563405   0.02540559\n",
            "   0.03856287]\n",
            " ...\n",
            " [ 0.00371693  0.01383313  0.03898747 ...  0.03097298  0.00352657\n",
            "  -0.04649899]\n",
            " [ 0.03321876 -0.05221993  0.00102754 ...  0.06288218 -0.06873414\n",
            "   0.02239523]\n",
            " [-0.07366481  0.13093603  0.10404676 ...  0.06868836 -0.08669124\n",
            "  -0.07602953]]\n",
            "11314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_anRKqJamjL",
        "outputId": "7bac957b-6583-4a74-ac81-1fd6f5f864d0"
      },
      "source": [
        "topic = np.array(topic)\n",
        "topic.shape\n",
        "len(set(topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McRJQDUrax5K",
        "outputId": "fb083eb2-de18-4b96-9d67-11d38e5cecf7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(d_matrix, topic, test_size=0.2, stratify =topic)\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9051, 64), (9051,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X98oLiyhooz",
        "outputId": "00a18d6f-4492-4285-f499-5e49b5a300e7"
      },
      "source": [
        "lgbm = LGBMClassifier(random_state = 42)\n",
        "lgbm.fit(x_train, y_train)\n",
        "pred = lgbm.predict(x_test)\n",
        "accuracy = accuracy_score(y_test,pred)\n",
        "\n",
        "print('정확도', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도 0.22536456031816174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HuLx4gubhTM",
        "outputId": "dd07e008-f47f-44ee-d7be-0a46511f0aae"
      },
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7dlOz_fb32V",
        "outputId": "c9d9251b-8e4f-4d5b-d42f-7d7fb4a36c99"
      },
      "source": [
        "print(\"* 학습용 데이터로 측정한 정확도 = %.2f\" % model.score(x_train, y_train))\n",
        "print(\"* 시험용 데이터로 측정한 정확도 = %.2f\" % model.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* 학습용 데이터로 측정한 정확도 = 0.19\n",
            "* 시험용 데이터로 측정한 정확도 = 0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FPu8JoKBL3A"
      },
      "source": [
        "# Sentencepice용 사전을 만들기 위해 corpusQA를 저장해 둔다.\n",
        "data_file = \"/content/drive/MyDrive/머신러닝/ChatBot/news_subject.txt\"\n",
        "with open(data_file, 'w', encoding='utf-8') as f:\n",
        "    for sent in subjects:\n",
        "        f.write(sent + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTBtrnvzBNhu"
      },
      "source": [
        "# Google의 Sentencepiece를 이용해서 vocabulary를 생성한다.\n",
        "# -----------------------------------------------------\n",
        "templates= \"--input={0:} \\\n",
        "            --pad_id=0 --pad_piece=<PAD>\\\n",
        "            --unk_id=1 --unk_piece=<UNK>\\\n",
        "            --bos_id=2 --bos_piece=<START>\\\n",
        "            --eos_id=3 --eos_piece=<END>\\\n",
        "            --model_prefix={1:} \\\n",
        "            --vocab_size={2:} \\\n",
        "            --character_coverage=0.9995 \\\n",
        "            --model_type=unigram\"\n",
        "\n",
        "VOCAB_SIZE = 6578\n",
        "model_prefix = \"/content/drive/MyDrive/머신러닝/ChatBot/news_subject\"\n",
        "params = templates.format(data_file, model_prefix, VOCAB_SIZE)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(params)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(model_prefix + '.model')\n",
        "\n",
        "with open(model_prefix + '.vocab', encoding='utf-8') as f:\n",
        "    vocab = [doc.strip().split('\\t') for doc in f]\n",
        "\n",
        "word2idx = {k:v for v, [k, _] in enumerate(vocab)}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3VskcsrBPCj"
      },
      "source": [
        "# string으로 조회\n",
        "sentence = subjects[1]\n",
        "enc = sp.encode_as_pieces(sentence)\n",
        "dec = sp.decode_pieces(enc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg7Hn96MBROr",
        "outputId": "8710812d-61b3-4c1c-cf7a-bf7dc45ac30f"
      },
      "source": [
        "# word index로 조회\n",
        "# idx = sp.encode_as_ids(sentence)\n",
        "# dec = sp.decode_ids(idx)\n",
        "print('\\n    문장:', sentence)\n",
        "print('Subwords:', enc)\n",
        "print('    복원:', dec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    문장: amusing atheists and agnostics\n",
            "Subwords: ['▁am', 'using', '▁atheists', '▁and', '▁agnostic', 's']\n",
            "    복원: amusing atheists and agnostics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIWj_51BBTNI"
      },
      "source": [
        "# word index로 변환한다.\n",
        "subject_idx = [sp.encode_as_ids(s) for s in subjects]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIzzb1vdBW6I",
        "outputId": "5ade376a-a234-4423-c1be-1ea564198e39"
      },
      "source": [
        "subject_idx[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[168, 446],\n",
              " [430, 743, 101, 13, 966, 4],\n",
              " [58, 2172, 1125, 7, 91, 20, 1204],\n",
              " [70, 14, 4578, 379, 2305, 6],\n",
              " [300, 808, 1050, 4705]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9s93HQrB5J9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
