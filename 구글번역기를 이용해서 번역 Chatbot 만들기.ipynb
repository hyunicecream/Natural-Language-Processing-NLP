{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "실습과제1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "15F94FUVW4ZPx6hjk4vN44r8fHgX0TVFb",
      "authorship_tag": "ABX9TyMQvl+TJJ2fNW5Q1l/LS9ds",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunicecream/Natural-Language-Processing-NLP-/blob/main/%EA%B5%AC%EA%B8%80%EB%B2%88%EC%97%AD%EA%B8%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%B4%EC%84%9C%20%EB%B2%88%EC%97%AD%20Chatbot%20%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX9Kk8RoSz7M",
        "outputId": "082e2200-9626-4aee-b413-c5fbe9ee2a0e"
      },
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.7/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2021.8.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.2.0)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2021.5.30)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b497APzqTh-U"
      },
      "source": [
        "import googletrans\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dot, Concatenate\n",
        "from tensorflow.keras.layers import Embedding, TimeDistributed, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "r0hQ5S3tTt3b",
        "outputId": "9997cd33-d2f7-46cf-8cf2-6fa57d069f89"
      },
      "source": [
        "mt_df = pd.read_csv('/content/drive/MyDrive/머신러닝/기계번역chatbot/machine_trans.csv')\n",
        "\n",
        "mt_df.head(20)"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡</td>\n",
              "      <td>12 o'clock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>I fell on the one.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>I want to go to 4 nights and 4 days.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>I want to go to three nights and four days.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>PPL serious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>SD card broke.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>SD card No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>SNS Why not do not do it?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>I know that SNS is a waste of time.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>SNS time wasted,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SNS보면 나만 빼고 다 행복해보여</td>\n",
              "      <td>SNS looks happy to see me only</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>가끔 궁금해</td>\n",
              "      <td>Sometimes I wonder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>가끔 뭐하는지 궁금해</td>\n",
              "      <td>I wonder what to do.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>가끔은 혼자인게 좋다</td>\n",
              "      <td>Sometimes it's good to be alone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>가난한 자의 설움</td>\n",
              "      <td>A poor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>가만 있어도 땀난다</td>\n",
              "      <td>It's sweaty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>가상화폐 쫄딱 망함</td>\n",
              "      <td>Virtual currency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>가스불 켜고 나갔어</td>\n",
              "      <td>I turned on the gas fire and went out.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>가스불 켜놓고 나온거 같아</td>\n",
              "      <td>I think I turned on gas fire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>가스비 너무 많이 나왔다</td>\n",
              "      <td>Gasby has been too much.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     source                                       target\n",
              "0                     12시 땡                                   12 o'clock\n",
              "1               1지망 학교 떨어졌어                           I fell on the one.\n",
              "2              3박4일 놀러가고 싶다         I want to go to 4 nights and 4 days.\n",
              "3           3박4일 정도 놀러가고 싶다  I want to go to three nights and four days.\n",
              "4                   PPL 심하네                                  PPL serious\n",
              "5                 SD카드 망가졌어                               SD card broke.\n",
              "6                   SD카드 안돼                                   SD card No\n",
              "7            SNS 맞팔 왜 안하지ㅠㅠ                    SNS Why not do not do it?\n",
              "8   SNS 시간낭비인 거 아는데 매일 하는 중          I know that SNS is a waste of time.\n",
              "9         SNS 시간낭비인데 자꾸 보게됨                             SNS time wasted,\n",
              "10      SNS보면 나만 빼고 다 행복해보여               SNS looks happy to see me only\n",
              "11                   가끔 궁금해                           Sometimes I wonder\n",
              "12              가끔 뭐하는지 궁금해                         I wonder what to do.\n",
              "13              가끔은 혼자인게 좋다              Sometimes it's good to be alone\n",
              "14                가난한 자의 설움                                       A poor\n",
              "15               가만 있어도 땀난다                                  It's sweaty\n",
              "16               가상화폐 쫄딱 망함                             Virtual currency\n",
              "17               가스불 켜고 나갔어       I turned on the gas fire and went out.\n",
              "18           가스불 켜놓고 나온거 같아                I think I turned on gas fire.\n",
              "19            가스비 너무 많이 나왔다                     Gasby has been too much."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpxPZ52FfzkM"
      },
      "source": [
        "question = mt_df['source']\n",
        "answer = mt_df['target']"
      ],
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP5LSbrwf81K",
        "outputId": "a85532ee-936c-45f6-b6dc-d063151e3d71"
      },
      "source": [
        "question, answer"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0                          12시 땡\n",
              " 1                    1지망 학교 떨어졌어\n",
              " 2                   3박4일 놀러가고 싶다\n",
              " 3                3박4일 정도 놀러가고 싶다\n",
              " 4                        PPL 심하네\n",
              "                   ...           \n",
              " 23641          티가 나니까 눈치가 보이는 거죠\n",
              " 23642               훔쳐보는 거 티나나봐요\n",
              " 23643                      설렜겠어요\n",
              " 23644    잘 헤어질 수 있는 사이 여부인 거 같아요\n",
              " 23645          도피성 결혼은 하지 않길 바라요\n",
              " Name: source, Length: 23646, dtype: object,\n",
              " 0                                         12 o'clock\n",
              " 1                                 I fell on the one.\n",
              " 2               I want to go to 4 nights and 4 days.\n",
              " 3        I want to go to three nights and four days.\n",
              " 4                                        PPL serious\n",
              "                             ...                     \n",
              " 23641        It looks noticeable because Ti is gone.\n",
              " 23642                         I'm going to steal it.\n",
              " 23643                                  I'll make it.\n",
              " 23644      I think it's whether I can break up well.\n",
              " 23645                     I hope not to be mourning.\n",
              " Name: target, Length: 23646, dtype: object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOnGXkjbtWkX",
        "outputId": "41bdd4fb-1c84-42ec-c0dd-e198f6c5253d"
      },
      "source": [
        "print('전체 샘플의 개수 =', len(mt_df))"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 개수 = 23646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I71WHBfxgKbB",
        "outputId": "6304164c-79fa-474f-d8a4-dde7fe8fcb9e"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9A4sC86Vb7q"
      },
      "source": [
        "import sentencepiece as spm\n",
        "# 인코더용 sentencepiece 단어 사전\n",
        "# Sentencepice용 사전을 만들기 위해 question + answer를 저장해 둔다.\n",
        "data_file = \"/content/drive/MyDrive/머신러닝/기계번역chatbot/machine_trans.txt\"\n",
        "with open(data_file, 'w', encoding='utf-8') as f:\n",
        "    for sent in source + target:\n",
        "        f.write(sent + '\\n')\n",
        "        \n",
        "# Google의 Sentencepiece를 이용해서 vocabulary를 생성한다.\n",
        "# -----------------------------------------------------\n",
        "templates= \"--input={} \\\n",
        "            --pad_id=0 --pad_piece=<PAD>\\\n",
        "            --unk_id=1 --unk_piece=<UNK>\\\n",
        "            --bos_id=2 --bos_piece=<BOS>\\\n",
        "            --eos_id=3 --eos_piece=<EOS>\\\n",
        "            --model_prefix={} \\\n",
        "            --vocab_size={} \\\n",
        "            --character_coverage=1.0 \\\n",
        "            --model_type=unigram\"\n",
        "\n",
        "ENC_VOCAB_SIZE = 20000\n",
        "model_prefix = \"/content/drive/MyDrive/머신러닝/기계번역chatbot/machine_trans_enc_model\"\n",
        "params = templates.format(data_file, model_prefix, VOCAB_SIZE)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(params)\n",
        "enc_sp = spm.SentencePieceProcessor()\n",
        "enc_sp.Load(model_prefix + '.model')\n",
        "with open(model_prefix + '.vocab', encoding='utf-8') as f:\n",
        "    vocab = [doc.strip().split('\\t') for doc in f]\n",
        "\n",
        "enc_word2idx = {k:v for v, [k, _] in enumerate(vocab)}\n",
        "enc_idx2word = {v:k for v, [k, _] in enumerate(vocab)}"
      ],
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-7TDgO1fsIz"
      },
      "source": [
        "import sentencepiece as spm\n",
        "# 디코더용 sentencepiece 단어 사전\n",
        "# Sentencepice용 사전을 만들기 위해 question + answer를 저장해 둔다.\n",
        "data_file = \"/content/drive/MyDrive/머신러닝/기계번역chatbot/machine_trans.txt\"\n",
        "with open(data_file, 'w', encoding='utf-8') as f:\n",
        "    for sent in source + target:\n",
        "        f.write(sent + '\\n')\n",
        "        \n",
        "# Google의 Sentencepiece를 이용해서 vocabulary를 생성한다.\n",
        "# -----------------------------------------------------\n",
        "templates= \"--input={} \\\n",
        "            --pad_id=0 --pad_piece=<PAD>\\\n",
        "            --unk_id=1 --unk_piece=<UNK>\\\n",
        "            --bos_id=2 --bos_piece=<BOS>\\\n",
        "            --eos_id=3 --eos_piece=<EOS>\\\n",
        "            --model_prefix={} \\\n",
        "            --vocab_size={} \\\n",
        "            --character_coverage=1.0 \\\n",
        "            --model_type=unigram\"\n",
        "\n",
        "DEC_VOCAB_SIZE = 20000\n",
        "model_prefix = \"/content/drive/MyDrive/머신러닝/기계번역chatbot/machine_trans_dec_model\"\n",
        "params = templates.format(data_file, model_prefix, VOCAB_SIZE)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(params)\n",
        "dec_sp = spm.SentencePieceProcessor()\n",
        "dec_sp.Load(model_prefix + '.model')\n",
        "with open(model_prefix + '.vocab', encoding='utf-8') as f:\n",
        "    vocab = [doc.strip().split('\\t') for doc in f]\n",
        "\n",
        "dec_word2idx = {k:v for v, [k, _] in enumerate(vocab)}\n",
        "dec_idx2word = {v:k for v, [k, _] in enumerate(vocab)}"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o1j-tDGhVGw"
      },
      "source": [
        "# 학습 데이터를 생성한다. (인코더 입력용, 디코더 입력용, 디코더 출력용)\n",
        "MAX_LEN = 15\n",
        "enc_input = []\n",
        "dec_input = []\n",
        "dec_output = []\n",
        "\n",
        "for Q, A in zip(question, answer):\n",
        "    # Encoder 입력\n",
        "    enc_i = sp.encode_as_ids(Q)\n",
        "    enc_input.append(enc_i)\n",
        "\n",
        "    # Decoder 입력, 출력\n",
        "    dec_i = [sp.bos_id()]   # <BOS>에서 시작함\n",
        "    dec_o = []\n",
        "    for ans in sp.encode_as_ids(A):\n",
        "        dec_i.append(ans)\n",
        "        dec_o.append(ans)\n",
        "    dec_o.append(sp.eos_id())   # Encoder 출력은 <EOS>로 끝남.        \n",
        "    \n",
        "    # dec_o는 <EOS>가 마지막에 들어있다. 나중에 pad_sequences()에서 <EOS>가\n",
        "    # 잘려 나가지 않도록 MAX_LEN 위치에 <EOS>를 넣어준다.\n",
        "    if len(dec_o) > MAX_LEN:\n",
        "        dec_o[MAX_LEN] = sp.eos_id()\n",
        "        \n",
        "    dec_input.append(dec_i)\n",
        "    dec_output.append(dec_o)"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBvM5v--hXqs"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "# 각 문장의 길이를 맞추고 남는 부분에 padding을 삽입한다.\n",
        "enc_input = pad_sequences(enc_input, maxlen=MAX_LEN, value = enc_sp.pad_id(), padding='post', truncating='post')\n",
        "dec_input = pad_sequences(dec_input, maxlen=MAX_LEN, value = dec_sp.pad_id(), padding='post', truncating='post')\n",
        "dec_output = pad_sequences(dec_output, maxlen=MAX_LEN, value = dec_sp.pad_id(), padding='post', truncating='post')"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFleNrX2hc27"
      },
      "source": [
        "# 사전과 학습 데이터를 저장한다.\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/enc_voc.pkl', 'wb') as f:\n",
        "    pickle.dump([enc_word2idx, enc_idx2word], f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/dec_voc.pkl', 'wb') as f:\n",
        "    pickle.dump([dec_word2idx, dec_idx2word], f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/enc_dec_data.pkl', 'wb') as f:\n",
        "    pickle.dump([enc_input, dec_input, dec_output], f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-3-EOuNhos2"
      },
      "source": [
        "# 단어 목록 dict를 읽어온다.\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/enc_voc.pkl', 'rb') as f:\n",
        "    enc_word2idx,  enc_idx2word = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/dec_voc.pkl', 'rb') as f:\n",
        "    dec_word2idx,  dec_idx2word = pickle.load(f)\n",
        "\n",
        "# 학습 데이터 : 인코딩, 디코딩 입력, 디코딩 출력을 읽어온다.\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/enc_dec_data.pkl', 'rb') as f:\n",
        "    trainXE, trainXD, trainYD = pickle.load(f)"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "197sAPMPJdQz"
      },
      "source": [
        "ENC_VOCAB_SIZE = len(enc_idx2word)\n",
        "EMB_SIZE = 128\n",
        "LSTM_HIDDEN = 128\n",
        "MODEL_PATH = '/content/drive/MyDrive/머신러닝/기계번역chatbot/translate_trained.h5'\n",
        "LOAD_MODEL = True\n",
        "\n",
        "# Encoder 출력과 decoder 출력으로 attention value를 생성하고,\n",
        "# decoder 출력 + attention value (concatenate)를 리턴한다.\n",
        "# x : encoder 출력, y : decoder 출력\n",
        "# LSTM time step = 4, EMB_SIZE = 3 이라면 각 텐서의 dimension은\n",
        "# 아래 주석과 같다.\n",
        "def Attention(x, y):\n",
        "    # step-1:\n",
        "    # decoder의 매 시점마다 encoder의 전체 시점과 dot-product을 수행한다.\n",
        "    score = Dot(axes=(2, 2))([y, x])                   # (1, 4, 4)\n",
        "    \n",
        "    # step-2:\n",
        "    # dot-product 결과를 확률분포로 만든다 (softmax)\n",
        "    # 이것이 attention score이다.\n",
        "    dist = Activation('softmax')(score)                # (1, 4, 4)\n",
        "\n",
        "    # step-3:\n",
        "    # Attention value를 계산한다.\n",
        "    attention = Dot(axes=(2, 1))([dist, x])\n",
        "\n",
        "    # step-4:\n",
        "    # decoder 출력과 attention을 concatenate 한다.\n",
        "    return Concatenate()([y, attention])    # (1, 4, 6)"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crWP-PNIJi78"
      },
      "source": [
        "DEC_VOCAB_SIZE = len(dec_idx2word)\n",
        "EMB_SIZE = 128\n",
        "LSTM_HIDDEN = 128\n",
        "MODEL_PATH = '/content/drive/MyDrive/머신러닝/기계번역chatbot/translate_trained.h5'\n",
        "LOAD_MODEL = True\n",
        "\n",
        "# Encoder 출력과 decoder 출력으로 attention value를 생성하고,\n",
        "# decoder 출력 + attention value (concatenate)를 리턴한다.\n",
        "# x : encoder 출력, y : decoder 출력\n",
        "# LSTM time step = 4, EMB_SIZE = 3 이라면 각 텐서의 dimension은\n",
        "# 아래 주석과 같다.\n",
        "def Attention(x, y):\n",
        "    # step-1:\n",
        "    # decoder의 매 시점마다 encoder의 전체 시점과 dot-product을 수행한다.\n",
        "    score = Dot(axes=(2, 2))([y, x])                   # (1, 4, 4)\n",
        "    \n",
        "    # step-2:\n",
        "    # dot-product 결과를 확률분포로 만든다 (softmax)\n",
        "    # 이것이 attention score이다.\n",
        "    dist = Activation('softmax')(score)                # (1, 4, 4)\n",
        "\n",
        "    # step-3:\n",
        "    # Attention value를 계산한다.\n",
        "    attention = Dot(axes=(2, 1))([dist, x])\n",
        "\n",
        "    # step-4:\n",
        "    # decoder 출력과 attention을 concatenate 한다.\n",
        "    return Concatenate()([y, attention])    # (1, 4, 6)"
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4HsxtkOJNIl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainXE, testXE = train_test_split(enc_input, test_size=0.2, random_state=42)\n",
        "trainXD, testXD = train_test_split(dec_input, test_size=0.2, random_state=42)\n",
        "trainYD, testYD = train_test_split(dec_output, test_size=0.2, random_state=42)"
      ],
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS9vCC8lCGxV",
        "outputId": "0dd28b68-a5f6-4369-92ad-5d6e89cbee0d"
      },
      "source": [
        "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
        "K.clear_session()\n",
        "wordEmbedding = Embedding(input_dim=ENC_VOCAB_SIZE, output_dim=EMB_SIZE)\n",
        "wordEmbedding1 = Embedding(input_dim=DEC_VOCAB_SIZE, output_dim=EMB_SIZE)\n",
        "\n",
        "# Encoder\n",
        "# -------\n",
        "# many-to-many로 구성한다. Attention value를 계산하기 위해 중간 출력이 필요하고\n",
        "# (return_sequences=True), decoder로 전달할 h와 c도 필요하다 (return_state = True)\n",
        "encoderX = Input(batch_shape=(None, trainXE.shape[1]))\n",
        "encEMB = wordEmbedding(encoderX)\n",
        "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
        "encLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
        "ey1, eh1, ec1 = encLSTM1(encEMB)    # LSTM 1층 \n",
        "ey2, eh2, ec2 = encLSTM2(ey1)       # LSTM 2층\n",
        "\n",
        "# Decoder\n",
        "# -------\n",
        "# many-to-many로 구성한다. target을 학습하기 위해서는 중간 출력이 필요하다.\n",
        "# 그리고 초기 h와 c는 encoder에서 출력한 값을 사용한다 (initial_state)\n",
        "# 최종 출력은 vocabulary의 인덱스인 one-hot 인코더이다.\n",
        "decoderX = Input(batch_shape=(None, trainXD.shape[1]))\n",
        "decEMB = wordEmbedding1(decoderX)\n",
        "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
        "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
        "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
        "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
        "att_dy2 = Attention(ey2, dy2)\n",
        "decOutput = TimeDistributed(Dense(DEC_VOCAB_SIZE, activation='softmax'))\n",
        "outputY = decOutput(att_dy2)\n",
        "\n",
        "# Model\n",
        "# -----\n",
        "model = Model([encoderX, decoderX], outputY)\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.0005), \n",
        "              loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 15, 128)      1152000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 15, 128)      1152000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 15, 128), (N 131584      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 15, 128), (N 131584      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 15, 128), (N 131584      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 15, 128), (N 131584      lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 15, 15)       0           lstm_3[0][0]                     \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 15, 15)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 15, 128)      0           activation[0][0]                 \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 15, 256)      0           lstm_3[0][0]                     \n",
            "                                                                 dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 15, 9000)     2313000     concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 5,143,336\n",
            "Trainable params: 5,143,336\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bPkYBwXSFda"
      },
      "source": [
        "if LOAD_MODEL:\n",
        "    model.load_weights(MODEL_PATH)"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPjz8ZP2CyjY",
        "outputId": "d843ff10-138e-4305-f21d-751ea9c87d1c"
      },
      "source": [
        "hist = model.fit([trainXE, trainXD], trainYD, validation_data=([testXE, testXD], testYD), batch_size = 256, epochs=100, shuffle=True)"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "74/74 [==============================] - 9s 61ms/step - loss: 0.6839 - val_loss: 1.9456\n",
            "Epoch 2/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.2591 - val_loss: 1.9438\n",
            "Epoch 3/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.2050 - val_loss: 1.9458\n",
            "Epoch 4/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.1813 - val_loss: 1.9540\n",
            "Epoch 5/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.1673 - val_loss: 1.9647\n",
            "Epoch 6/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.1573 - val_loss: 1.9678\n",
            "Epoch 7/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.1498 - val_loss: 1.9760\n",
            "Epoch 8/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.1441 - val_loss: 1.9831\n",
            "Epoch 9/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1399 - val_loss: 1.9888\n",
            "Epoch 10/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.1358 - val_loss: 1.9946\n",
            "Epoch 11/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1325 - val_loss: 2.0059\n",
            "Epoch 12/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1282 - val_loss: 2.0085\n",
            "Epoch 13/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1257 - val_loss: 2.0124\n",
            "Epoch 14/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1247 - val_loss: 2.0162\n",
            "Epoch 15/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.1236 - val_loss: 2.0183\n",
            "Epoch 16/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1201 - val_loss: 2.0219\n",
            "Epoch 17/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1172 - val_loss: 2.0255\n",
            "Epoch 18/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1151 - val_loss: 2.0272\n",
            "Epoch 19/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1138 - val_loss: 2.0388\n",
            "Epoch 20/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1114 - val_loss: 2.0332\n",
            "Epoch 21/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1095 - val_loss: 2.0486\n",
            "Epoch 22/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1074 - val_loss: 2.0461\n",
            "Epoch 23/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.1041 - val_loss: 2.0543\n",
            "Epoch 24/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.1004 - val_loss: 2.0596\n",
            "Epoch 25/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0971 - val_loss: 2.0662\n",
            "Epoch 26/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.0943 - val_loss: 2.0691\n",
            "Epoch 27/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0919 - val_loss: 2.0734\n",
            "Epoch 28/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0890 - val_loss: 2.0765\n",
            "Epoch 29/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0875 - val_loss: 2.0887\n",
            "Epoch 30/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0860 - val_loss: 2.0960\n",
            "Epoch 31/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0861 - val_loss: 2.0915\n",
            "Epoch 32/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0864 - val_loss: 2.0924\n",
            "Epoch 33/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0844 - val_loss: 2.1029\n",
            "Epoch 34/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0841 - val_loss: 2.1012\n",
            "Epoch 35/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0825 - val_loss: 2.1081\n",
            "Epoch 36/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0798 - val_loss: 2.1112\n",
            "Epoch 37/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0746 - val_loss: 2.1135\n",
            "Epoch 38/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0724 - val_loss: 2.1304\n",
            "Epoch 39/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0705 - val_loss: 2.1235\n",
            "Epoch 40/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0691 - val_loss: 2.1233\n",
            "Epoch 41/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0705 - val_loss: 2.1311\n",
            "Epoch 42/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0684 - val_loss: 2.1380\n",
            "Epoch 43/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0660 - val_loss: 2.1475\n",
            "Epoch 44/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0650 - val_loss: 2.1470\n",
            "Epoch 45/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0647 - val_loss: 2.1541\n",
            "Epoch 46/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0619 - val_loss: 2.1622\n",
            "Epoch 47/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0593 - val_loss: 2.1671\n",
            "Epoch 48/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0606 - val_loss: 2.1655\n",
            "Epoch 49/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0615 - val_loss: 2.1730\n",
            "Epoch 50/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0606 - val_loss: 2.1729\n",
            "Epoch 51/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0592 - val_loss: 2.1694\n",
            "Epoch 52/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0643 - val_loss: 2.1766\n",
            "Epoch 53/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0633 - val_loss: 2.1806\n",
            "Epoch 54/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0598 - val_loss: 2.1793\n",
            "Epoch 55/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0538 - val_loss: 2.1833\n",
            "Epoch 56/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0482 - val_loss: 2.1944\n",
            "Epoch 57/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0431 - val_loss: 2.1950\n",
            "Epoch 58/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0396 - val_loss: 2.1997\n",
            "Epoch 59/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0368 - val_loss: 2.2085\n",
            "Epoch 60/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0346 - val_loss: 2.2163\n",
            "Epoch 61/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0333 - val_loss: 2.2261\n",
            "Epoch 62/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0320 - val_loss: 2.2313\n",
            "Epoch 63/100\n",
            "74/74 [==============================] - 3s 46ms/step - loss: 0.0312 - val_loss: 2.2398\n",
            "Epoch 64/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0314 - val_loss: 2.2372\n",
            "Epoch 65/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0325 - val_loss: 2.2449\n",
            "Epoch 66/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0334 - val_loss: 2.2427\n",
            "Epoch 67/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0413 - val_loss: 2.2515\n",
            "Epoch 68/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0815 - val_loss: 2.2453\n",
            "Epoch 69/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.1345 - val_loss: 2.2331\n",
            "Epoch 70/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1119 - val_loss: 2.2088\n",
            "Epoch 71/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0779 - val_loss: 2.2001\n",
            "Epoch 72/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0525 - val_loss: 2.2061\n",
            "Epoch 73/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0377 - val_loss: 2.2188\n",
            "Epoch 74/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0307 - val_loss: 2.2262\n",
            "Epoch 75/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0276 - val_loss: 2.2325\n",
            "Epoch 76/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0255 - val_loss: 2.2402\n",
            "Epoch 77/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0241 - val_loss: 2.2466\n",
            "Epoch 78/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0231 - val_loss: 2.2529\n",
            "Epoch 79/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0222 - val_loss: 2.2556\n",
            "Epoch 80/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0214 - val_loss: 2.2650\n",
            "Epoch 81/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0208 - val_loss: 2.2704\n",
            "Epoch 82/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0201 - val_loss: 2.2771\n",
            "Epoch 83/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0195 - val_loss: 2.2824\n",
            "Epoch 84/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0190 - val_loss: 2.2894\n",
            "Epoch 85/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0185 - val_loss: 2.2922\n",
            "Epoch 86/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0181 - val_loss: 2.2982\n",
            "Epoch 87/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0178 - val_loss: 2.3049\n",
            "Epoch 88/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0177 - val_loss: 2.3102\n",
            "Epoch 89/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0178 - val_loss: 2.3142\n",
            "Epoch 90/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0180 - val_loss: 2.3163\n",
            "Epoch 91/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0206 - val_loss: 2.3168\n",
            "Epoch 92/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0293 - val_loss: 2.3226\n",
            "Epoch 93/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0945 - val_loss: 2.3090\n",
            "Epoch 94/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.1397 - val_loss: 2.2829\n",
            "Epoch 95/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0948 - val_loss: 2.2613\n",
            "Epoch 96/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0575 - val_loss: 2.2556\n",
            "Epoch 97/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0354 - val_loss: 2.2601\n",
            "Epoch 98/100\n",
            "74/74 [==============================] - 3s 45ms/step - loss: 0.0251 - val_loss: 2.2703\n",
            "Epoch 99/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0203 - val_loss: 2.2797\n",
            "Epoch 100/100\n",
            "74/74 [==============================] - 3s 44ms/step - loss: 0.0181 - val_loss: 2.2869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMES058tC0mi"
      },
      "source": [
        "# 학습 결과를 저장한다\n",
        "MODEL_PATH = '/content/drive/MyDrive/머신러닝/기계번역chatbot/translate_trained.h5'\n",
        "model.save_weights(MODEL_PATH)"
      ],
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UiOHpwL6C3NZ",
        "outputId": "46f0d1f2-01c4-41f3-ec31-bba546acb430"
      },
      "source": [
        "# Loss history를 그린다\n",
        "plt.plot(hist.history['loss'], label='Train loss')\n",
        "plt.plot(hist.history['val_loss'], label='Validation loss')\n",
        "plt.legend()\n",
        "plt.title(\"Loss history\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djq9nIhREUI9"
      },
      "source": [
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/translate_train_test.pkl', 'wb') as f:\n",
        "    pickle.dump([trainXE, trainXD, trainYD, testXE, testXD, testYD], f, pickle.HIGHEST_PROTOCOL) "
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaHmo5-4MJiC",
        "outputId": "71c7a7e3-a44f-4a71-f84f-217d52f20d8e"
      },
      "source": [
        "# STEP3\n",
        "!!pip install sentencepiece"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaG7vIpUMNFR"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.layers import Embedding, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import sentencepiece as spm\n",
        "import numpy as np\n",
        "import pickle\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUHUxU4aMRkA"
      },
      "source": [
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/enc_voc.pkl', 'rb') as f:\n",
        "  enc_word2idx, enc_idx2word = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/dec_voc.pkl', 'rb') as f:\n",
        "  dec_word2idx, dec_idx2word = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/머신러닝/기계번역chatbot/translate_train_test.pkl', 'rb') as f:\n",
        "  trainXE, trainXD, trainYD, testXE, testXD, testYD = pickle.load(f)"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itAqqClKMW7k",
        "outputId": "95d59c15-2ef1-4ab0-804d-774c2c2225e0"
      },
      "source": [
        "ENC_MAX_LEN = 15\n",
        "DEC_MAX_LEN = 15\n",
        "ENC_VOCAB_SIZE = len(enc_idx2word)\n",
        "DEC_VOCAB_SIZE = len(dec_idx2word)\n",
        "EMB_SIZE = 128\n",
        "LSTM_HIDDEN = 128\n",
        "MODEL_PATH = '/content/drive/MyDrive/머신러닝/기계번역chatbot/translate_trained.h5'\n",
        "\n",
        "# 데이터 전처리 과정에서 생성한 SentencePiece model을 불러온다.\n",
        "SPM_ENC_MODEL = \"/content/drive/MyDrive/머신러닝/기계번역chatbot/machine_trans_enc_model.model\"\n",
        "enc_sp = spm.SentencePieceProcessor()\n",
        "enc_sp.Load(SPM_ENC_MODEL)\n",
        "\n",
        "SPM_DEC_MODEL = \"/content/drive/MyDrive/머신러닝/기계번역chatbot/machine_trans_dec_model.model\"\n",
        "dec_sp = spm.SentencePieceProcessor()\n",
        "dec_sp.Load(SPM_DEC_MODEL)"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwqk_doWZE00"
      },
      "source": [
        "# Encoder 출력과 decoder 출력으로 attention value를 생성하고,\n",
        "# decoder 출력 + attention value (concatenate)를 리턴한다.\n",
        "# x : encoder 출력, y : decoder 출력\n",
        "# LSTM time step = 4, SMB_SIZE = 3 이라면 각 텐서의 dimension은\n",
        "# 아래 주석과 같다.\n",
        "def Attention(x, y):\n",
        "    # step-1:\n",
        "    # decoder의 매 시점마다 encoder의 전체 시점과 dot-product을 수행한다.\n",
        "    score = Dot(axes=(2, 2))([y, x])                   # (1, 4, 4)\n",
        "    \n",
        "    # step-2:\n",
        "    # dot-product 결과를 확률분포로 만든다 (softmax)\n",
        "    # 이것이 attention score이다.\n",
        "    dist = Activation('softmax')(score)                # (1, 4, 4)\n",
        "\n",
        "    # step-3:\n",
        "    # Attention value를 계산한다.\n",
        "    attention = Dot(axes=(2, 1))([dist, x])\n",
        "\n",
        "    # step-4:\n",
        "    # decoder 출력과 attention을 concatenate 한다.\n",
        "    return Concatenate()([y, attention])    # (1, 4, 6)"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOs0kDuoM9xU"
      },
      "source": [
        "# 워드 임베딩 레이어. Encoder와 decoder에서 공동으로 사용한다.\n",
        "K.clear_session()\n",
        "wordEmbedding = Embedding(input_dim=ENC_VOCAB_SIZE, output_dim=EMB_SIZE)\n",
        "wordEmbedding1 = Embedding(input_dim=DEC_VOCAB_SIZE, output_dim=EMB_SIZE)\n",
        "\n",
        "# Encoder\n",
        "# -------\n",
        "encoderX = Input(batch_shape=(None, MAX_LEN))\n",
        "encEMB = wordEmbedding(encoderX)\n",
        "encLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
        "encLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state = True)\n",
        "ey1, eh1, ec1 = encLSTM1(encEMB)      # LSTM 1층 \n",
        "ey2, eh2, ec2 = encLSTM2(ey1)         # LSTM 2층\n",
        "\n",
        "# Decoder\n",
        "# -------\n",
        "# Decoder는 1개 단어씩을 입력으로 받는다. 학습 때와 달리 문장 전체를 받아\n",
        "# recurrent하는 것이 아니라, 단어 1개씩 입력 받아서 다음 예상 단어를 확인한다.\n",
        "# chatting()에서 for 문으로 단어 별로 recurrent 시킨다.\n",
        "# 따라서 batch_shape = (None, 1)이다. 즉, time_step = 1이다. 그래도 네트워크\n",
        "# 파라메터는 동일하다.\n",
        "decoderX = Input(batch_shape=(None, 1))\n",
        "decEMB = wordEmbedding1(decoderX)\n",
        "decLSTM1 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
        "decLSTM2 = LSTM(LSTM_HIDDEN, return_sequences=True, return_state=True)\n",
        "dy1, _, _ = decLSTM1(decEMB, initial_state = [eh1, ec1])\n",
        "dy2, _, _ = decLSTM2(dy1, initial_state = [eh2, ec2])\n",
        "att_dy2 = Attention(ey2, dy2)\n",
        "decOutput = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))\n",
        "outputY = decOutput(att_dy2)\n",
        "\n",
        "# Model\n",
        "# -----\n",
        "model = Model([encoderX, decoderX], outputY)\n",
        "model.load_weights(MODEL_PATH)"
      ],
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdODZDczNKx-"
      },
      "source": [
        "# Chatting용 model\n",
        "model_enc = Model(encoderX, [eh1, ec1, eh2, ec2, ey2])\n",
        "\n",
        "ih1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
        "ic1 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
        "ih2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
        "ic2 = Input(batch_shape = (None, LSTM_HIDDEN))\n",
        "ey = Input(batch_shape = (None, MAX_LEN, LSTM_HIDDEN))\n",
        "\n",
        "dec_output1, dh1, dc1 = decLSTM1(decEMB, initial_state = [ih1, ic1])\n",
        "dec_output2, dh2, dc2 = decLSTM2(dec_output1, initial_state = [ih2, ic2])\n",
        "dec_attention = Attention(ey, dec_output2)\n",
        "dec_output = decOutput(dec_attention)\n",
        "model_dec = Model([decoderX, ih1, ic1, ih2, ic2, ey], \n",
        "                  [dec_output, dh1, dc1, dh2, dc2])"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emdc3NE0NOpH"
      },
      "source": [
        "# Question을 입력받아 Answer를 생성한다.\n",
        "def genAnswer(question):\n",
        "    question = question[np.newaxis, :]\n",
        "    init_h1, init_c1, init_h2, init_c2, enc_y = model_enc.predict(question)\n",
        "\n",
        "    # 시작 단어는 <BOS>로 한다.\n",
        "    word = np.array(sp.bos_id()).reshape(1, 1)\n",
        "\n",
        "    answer = []\n",
        "    for i in range(MAX_LEN):\n",
        "        dY, next_h1, next_c1, next_h2, next_c2 = \\\n",
        "            model_dec.predict([word, init_h1, init_c1, init_h2, init_c2, enc_y])\n",
        "        \n",
        "        # 디코더의 출력은 vocabulary에 대응되는 one-hot이다.\n",
        "        # argmax로 해당 단어를 채택한다.\n",
        "        nextWord = np.argmax(dY[0, 0])\n",
        "\n",
        "        # 예상 단어가 <EOS>이거나 <PAD>이면 더 이상 예상할 게 없다.\n",
        "        if nextWord == sp.eos_id() or nextWord == sp.pad_id():\n",
        "            break\n",
        "        \n",
        "        # 다음 예상 단어인 디코더의 출력을 answer에 추가한다.\n",
        "        answer.append(idx2word[nextWord])\n",
        "        \n",
        "        # 디코더의 다음 recurrent를 위해 입력 데이터와 hidden 값을\n",
        "        # 준비한다. 입력은 word이고, hidden은 h와 c이다.\n",
        "        word = np.array(nextWord).reshape(1,1)\n",
        "    \n",
        "        init_h1 = next_h1\n",
        "        init_c1 = next_c1\n",
        "        init_h2 = next_h2\n",
        "        init_c2 = next_c2\n",
        "        \n",
        "    return sp.decode_pieces(answer)"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aC0w29sNQqg"
      },
      "source": [
        "def make_question(que_string):\n",
        "    q_idx = []\n",
        "    for x in sp.encode_as_pieces(que_string):\n",
        "        if x in word2idx:\n",
        "            q_idx.append(word2idx[x])\n",
        "        else:\n",
        "            q_idx.append(sp.unk_id())   # out-of-vocabulary (OOV)\n",
        "    \n",
        "    # <PAD>를 삽입한다.\n",
        "    if len(q_idx) < MAX_LEN:\n",
        "        q_idx.extend([sp.pad_id()] * (MAX_LEN - len(q_idx)))\n",
        "    else:\n",
        "        q_idx = q_idx[0:MAX_LEN]\n",
        "    return q_idx"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4tddtJENU5j",
        "outputId": "fdee9d22-4e7d-4616-ef80-89513d9d84d0"
      },
      "source": [
        "# BLEU 평가\n",
        "bleu_list = []\n",
        "for que_str, reference in zip(question[:10], answer[:10]):\n",
        "    q_idx = make_question(que_str)\n",
        "    candidate = genAnswer(np.array(q_idx))\n",
        "\n",
        "    # BLEU를 측정한다.\n",
        "    # 기계번역의 reference는 어느정도 객관성이 있지만, 일상 대화용 챗봇의 reference는 매우 주관적이기 때문에,\n",
        "    # test data로 측정한 챗봇의 BLEU는 매우 낮을 수밖에 없다. 특정 업무를 위한 챗봇의 reference는 어느정도\n",
        "    # 객관성이 있을 수 있다.\n",
        "    #\n",
        "    # 1. 짧은 문장이 많기 때문에 단어가 아닌 subword 단위로 BLEU를 측정한다.\n",
        "    # 2. (Papineni et al. 2002)은 micro-average를 사용했지만, 여기서는 단순 평균인 macro-average를 사용한다.\n",
        "    reference = sp.encode_as_pieces(reference)\n",
        "    candidate = sp.encode_as_pieces(candidate)\n",
        "\n",
        "    bleu = sentence_bleu(reference, candidate, weights=[1/2., 1/2.])\n",
        "    bleu_list.append(bleu)\n",
        "    print(que_str, '-->', sp.decode_pieces(candidate), ':', np.round(bleu, 4))\n",
        "print('Average BLEU score =', np.round(np.mean(bleu_list), 4))"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "12시 땡 --> 12 o'clock : 0.5\n",
            "1지망 학교 떨어졌어 --> I fell on the one. : 0.4082\n",
            "3박4일 놀러가고 싶다 --> I want to go to 4 nights and 4 days. : 0.4082\n",
            "3박4일 정도 놀러가고 싶다 --> I want to go to three nights and four days. : 0.4082\n",
            "PPL 심하네 --> PPL serious : 0.7071\n",
            "SD카드 망가졌어 --> SD card broke. : 0.6325\n",
            "SD카드 안돼 --> SD card No : 0.4472\n",
            "SNS 맞팔 왜 안하지ㅠㅠ --> SNS Why not do not do it? : 0.4714\n",
            "SNS 시간낭비인 거 아는데 매일 하는 중 --> I know that SNS is a waste of time. : 0.3162\n",
            "SNS 시간낭비인데 자꾸 보게됨 --> SNS time wasted, : 0.4472\n",
            "Average BLEU score = 0.4746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJGJDdF4NW3c"
      },
      "source": [
        "# Chatting\n",
        "# dummy : 최초 1회는 모델을 로드하는데 약간의 시간이 걸리므로 이것을 가리기 위함.\n",
        "def chatting(n=100):\n",
        "    for i in range(n):\n",
        "        question = input('Q : ')\n",
        "        \n",
        "        if  question == 'quit':\n",
        "            break\n",
        "        \n",
        "        q_idx = make_question(question)\n",
        "        answer = genAnswer(np.array(q_idx))\n",
        "        print('A :', answer)"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xGcKrXgNdDW",
        "outputId": "402010cb-0484-4308-8235-7fc179d61f46"
      },
      "source": [
        "####### Chatting 시작 #######\n",
        "print(\"\\nSeq2Seq ChatBot (ver. 1.0)\")\n",
        "print(\"Chatting 모듈을 로드하고 있습니다 ...\")\n",
        "\n",
        "# 처음 1회는 시간이 걸리기 때문에 dummy question을 입력한다.\n",
        "answer = genAnswer(np.zeros(MAX_LEN))\n",
        "print(\"ChatBot이 준비 됐습니다.\")\n",
        "\n",
        "# 채팅을 시작한다.\n",
        "chatting(100)"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Seq2Seq ChatBot (ver. 1.0)\n",
            "Chatting 모듈을 로드하고 있습니다 ...\n",
            "ChatBot이 준비 됐습니다.\n",
            "Q : 12시 떙\n",
            "A : Perfect\n",
            "Q : 가스비 너무 많이 나왔다\t\n",
            "A : Gasby has been too much.\n",
            "Q : quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpnE3TWHcMcq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}